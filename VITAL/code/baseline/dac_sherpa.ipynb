{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofEEnER0p6zL",
        "outputId": "924e4dd0-03a7-47c8-fd3e-476083a49bfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'private' already exists and is not an empty directory.\n",
            "Cloning into 'maril'...\n",
            "remote: Enumerating objects: 131, done.\u001b[K\n",
            "remote: Counting objects: 100% (131/131), done.\u001b[K\n",
            "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
            "remote: Total 131 (delta 88), reused 84 (delta 58), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (131/131), 2.78 MiB | 19.47 MiB/s, done.\n",
            "Resolving deltas: 100% (88/88), done.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.18.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras-multi-head in /usr/local/lib/python3.7/dist-packages (0.29.0)\n",
            "Requirement already satisfied: keras-self-attention==0.51.0 in /usr/local/lib/python3.7/dist-packages (from keras-multi-head) (0.51.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-self-attention==0.51.0->keras-multi-head) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "!rm -rf maril\n",
        "!git clone https://github.com/danishgufran/private.git\n",
        "!git clone --depth=1 https://danishgufran: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@github.com/danishgufran/maril.git\n",
        "!pip install tensorflow-addons\n",
        "!pip install keras-multi-head"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image as im\n",
        "import copy\n",
        "from copy import deepcopy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D , LSTM, Attention\n",
        "from tensorflow.keras.losses import *\n",
        "from tensorflow.keras.optimizers import*\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.regularizers import l1, l2\n",
        "import random as random\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "\n",
        "\n",
        "import private.Stone_Seth.Seth\n",
        "from private.Stone_Seth.Seth import fetch_seth, Devices, Floorplan, get_mac_ids\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from maril.data import Devices, Floorplan, build_dataset\n",
        "from maril.helpers import compute_distances\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# from MKLpy.algorithms import EasyMKL\n",
        "# from MKLpy.multiclass import OneVsRestMKLClassifier, OneVsOneMKLClassifier\n",
        "# from MKLpy.algorithms import AverageMKL\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import time"
      ],
      "metadata": {
        "id": "jZar_kKB1tNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import namedtuple\n",
        "from dataclasses import dataclass, asdict\n",
        "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from maril.Anvil import Anvil\n",
        "from maril.data import Floorplan, build_dataset, Devices\n",
        "from maril.helpers import compute_distances, import_model\n",
        "from maril.Sherpa.Sherpa import Sherpa\n",
        "from tqdm.auto import tqdm\n",
        "import itertools\n",
        "from maril.Baselines.Baselines import Baseline\n",
        "from maril.helpers import make_images\n",
        "import tensorflow as tf\n",
        "\n",
        "def knn(\n",
        "    train_device,\n",
        "    floorplan,\n",
        "    data_basepath=\"maril/Data/\",\n",
        "    targets=[\"label\"],\n",
        "    nn=3,\n",
        "    build_model=KNN,\n",
        "    tqdm_disable=True,\n",
        "):\n",
        "\n",
        "    final = []\n",
        "    mean_error = []\n",
        "    results_error = {}\n",
        "    results_sd = {}\n",
        "\n",
        "    if floorplan == 'engr0':\n",
        "      shp = 206\n",
        "    if floorplan == 'engr1':\n",
        "      shp = 202\n",
        "    if floorplan == 'glover':\n",
        "        shp = 78\n",
        "    if floorplan == 'sciences':\n",
        "        shp = 172\n",
        "    if floorplan == 'libstudy':\n",
        "        shp = 319\n",
        "\n",
        "\n",
        "    # dev = ['HTC','LG','MOTO','OP3','S7']\n",
        "    # for d in dev:\n",
        "    train_df, test_df, train_waps, lbl2cords = build_dataset(\n",
        "        train_device,\n",
        "        floorplan,\n",
        "        base_path=data_basepath,\n",
        "    )\n",
        "\n",
        "    td = 'i12p'\n",
        "    train_df_rst_1, _, train_macs_rst_1, lbl2cord_rst_1 = build_dataset(\n",
        "      td,\n",
        "      floorplan,\n",
        "  )\n",
        "    missing_waps_rst = list(set(train_waps) - set(train_macs_rst_1))\n",
        "    _df = train_df_rst_1.copy()  # supresses fragmented df warning\n",
        "    _df[missing_waps_rst] = -100\n",
        "    train_y = _df[\"label\"].values.flatten()\n",
        "    _df = _df.drop(columns=['label','x','y'])\n",
        "    _df = (_df[:] + 100)/100\n",
        "    train_x = _df[:].values.astype(float)\n",
        "    \n",
        "\n",
        "    print('one', train_x.shape)\n",
        "\n",
        "    dev = ['i12p','pxl4','nk7']\n",
        "    for d in dev:\n",
        "      # if self.floorplan == 'engr0':\n",
        "\n",
        "      get_train, _, get_mac, get_lbl2cord = build_dataset(\n",
        "        d,\n",
        "        floorplan,\n",
        "    )\n",
        "      missing_waps_new = list(set(get_mac) - set(train_macs_rst_1))\n",
        "      col = train_df_rst_1.copy()  # supresses fragmented df warning\n",
        "      col[missing_waps_new] = -100\n",
        "      temp_y = col[\"label\"].values.flatten()\n",
        "      col = col.drop(columns=['label','x','y'])\n",
        "\n",
        "      col = (col[:] + 100)/100\n",
        "      temp_x = col[:].values.astype(float)\n",
        "\n",
        "\n",
        "      # autoencoder = build_model(temp_x.shape[1], temp_x)\n",
        "      # temp_x = autoencoder.predict(temp_x)\n",
        "\n",
        "\n",
        "\n",
        "      train_x = np.resize(train_x,(train_y.shape[0],temp_x.shape[-1]))\n",
        "      print(temp_x.shape)\n",
        "      train_x = np.concatenate((train_x, temp_x), axis=0)\n",
        "      train_y = np.concatenate((train_y, temp_y), axis=0)\n",
        "    print(train_x.shape)\n",
        "\n",
        "    # target label\n",
        "    true_y = train_df[targets].values.flatten()\n",
        "\n",
        "    # train model\n",
        "    model = build_model(n_neighbors=nn)\n",
        "\n",
        "    # fit model\n",
        "    model.fit(\n",
        "        np.array(train_x),\n",
        "        np.array(train_y),\n",
        "    )\n",
        "\n",
        "    # test on self\n",
        "\n",
        "    dev = ['i12p','pxl4','nk7']\n",
        "    for dev_name in dev:\n",
        "      # build data\n",
        "      train_df, test_df, macs, lbl2cords = build_dataset(\n",
        "          dev_name,\n",
        "          floorplan\n",
        "      )\n",
        "\n",
        "      missing_waps = list(set(train_macs_rst_1) - set(macs))\n",
        "      test_df = test_df.copy()  # supresses fragmented df warning\n",
        "      test_df[missing_waps] = -100\n",
        "      test_y = test_df[\"label\"].values.flatten()\n",
        "      test_df.drop(columns=['label','x','y'])\n",
        "      test_df = (test_df[:] + 100)/100\n",
        "      test_x = test_df[train_macs_rst_1].values.astype(float)\n",
        "      \n",
        "      test_x = np.resize(test_x,(test_x.shape[0],temp_x.shape[-1]))\n",
        "\n",
        "      pred_y = model.predict(test_x)\n",
        "      \n",
        "      test_y = test_df[targets].values.flatten()\n",
        "\n",
        "      print(floorplan)\n",
        "      \n",
        "\n",
        "      error = np.mean(\n",
        "              compute_distances(\n",
        "                  pred_y,\n",
        "                  test_y\n",
        "              )\n",
        "          )\n",
        "      print(error)\n",
        "      final.append(error)\n",
        "    print(final)\n",
        "\n",
        "\n",
        "    return results_error, results_sd, final\n",
        "\n",
        "def sherpa(\n",
        "    train_device,\n",
        "    floorplan,\n",
        "    data_basepath=\"maril/Data/\",\n",
        "    targets=[\"label\"],\n",
        "    nn=3,\n",
        "    tqdm_disable=True,\n",
        "):\n",
        "    return knn(\n",
        "        train_device,\n",
        "        floorplan,\n",
        "        data_basepath=data_basepath,\n",
        "        targets=targets,\n",
        "        nn=nn,\n",
        "        build_model=Sherpa,\n",
        "        tqdm_disable=tqdm_disable,\n",
        "    )\n",
        "\n",
        "def main():\n",
        "\n",
        "  fp = ['engr0', 'engr1', 'glover', 'sciences', 'libstudy']\n",
        "  for f in fp:\n",
        "    sherpa('i12p', f)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvaAf9T_xOwM",
        "outputId": "2aff6805-8842-4d21-a779-65604196c625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "one (164, 176)\n",
            "(164, 176)\n",
            "(164, 342)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3645: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self[col] = value\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
            "  warnings.warn(PearsonRConstantInputWarning())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(164, 335)\n",
            "(656, 335)\n",
            "engr0\n",
            "1.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
            "  warnings.warn(PearsonRConstantInputWarning())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "engr0\n",
            "1.2047619047619047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
            "  warnings.warn(PearsonRConstantInputWarning())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "engr0\n",
            "1.2047619047619047\n",
            "[1.2, 1.2047619047619047, 1.2047619047619047]\n",
            "one (168, 159)\n",
            "(168, 159)\n",
            "(168, 271)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3645: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self[col] = value\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
            "  warnings.warn(PearsonRConstantInputWarning())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(168, 256)\n",
            "(672, 256)\n",
            "engr1\n",
            "1.2049999999999998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
            "  warnings.warn(PearsonRConstantInputWarning())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "engr1\n",
            "1.209767441860465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
            "  warnings.warn(PearsonRConstantInputWarning())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "engr1\n",
            "1.2047619047619047\n",
            "[1.2049999999999998, 1.209767441860465, 1.2047619047619047]\n",
            "one (148, 177)\n",
            "(148, 177)\n",
            "(148, 251)\n",
            "(148, 239)\n",
            "(592, 239)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
            "  warnings.warn(PearsonRConstantInputWarning())\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
            "  warnings.warn(PearsonRConstantInputWarning())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glover\n",
            "1.1800000000000002\n",
            "glover\n",
            "1.1847368421052633\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
            "  warnings.warn(PearsonRConstantInputWarning())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glover\n",
            "1.1847368421052633\n",
            "[1.1800000000000002, 1.1847368421052633, 1.1847368421052633]\n",
            "one (168, 264)\n",
            "(168, 264)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3645: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self[col] = value\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
            "  warnings.warn(PearsonRConstantInputWarning())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(168, 498)\n",
            "(168, 406)\n",
            "(672, 406)\n",
            "sciences\n",
            "1.2049999999999998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
            "  warnings.warn(PearsonRConstantInputWarning())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sciences\n",
            "1.209767441860465\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
            "  warnings.warn(PearsonRConstantInputWarning())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sciences\n",
            "1.209767441860465\n",
            "[1.2049999999999998, 1.209767441860465, 1.209767441860465]\n",
            "one (172, 274)\n",
            "(172, 274)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3645: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self[col] = value\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
            "  warnings.warn(PearsonRConstantInputWarning())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(172, 427)\n",
            "(172, 389)\n",
            "(688, 389)\n",
            "libstudy\n",
            "1.21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
            "  warnings.warn(PearsonRConstantInputWarning())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "libstudy\n",
            "1.2147727272727271\n",
            "libstudy\n",
            "1.209767441860465\n",
            "[1.21, 1.2147727272727271, 1.209767441860465]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/stats/stats.py:4023: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
            "  warnings.warn(PearsonRConstantInputWarning())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sherpa_no_dam = [[2.065573770491805, 1.5245901639344273, 0.21311475409836078, 2.0685301620901484, 1.764866463106434, 1.5081967213114769],\n",
        "          [1.7980653289451094, 1.4545652481179323, 0.10416666666666669, 2.2510130661987717, 1.5221769812967914, 1.2484884716320621],\n",
        "          [2.012852249247597, 1.3896718089768398, 0.4029796624500576, 1.7892066150162698, 1.7408773929711023, 1.453658166367923],\n",
        "          [5.187525299382937, 1.5012804505254305, 0.31773293258909385, 1.9919799584135067, 2.195467787476551, 2.079338452420637],\n",
        "          [2.8607726131662563, 2.1738019089781915, 0.016666666666666666, 2.269787578072531,3.310713156183941, 2.3602722601254125]]"
      ],
      "metadata": {
        "id": "NUq0X1o2yBKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sherpa_dam = [[2.065573770491805, 1.5245901639344273, 0.21311475409836078, 2.0685301620901484, 1.764866463106434, 1.5081967213114769],\n",
        "          [1.7980653289451094, 1.4545652481179323, 0.10416666666666669, 2.2510130661987717, 1.5221769812967914, 1.2484884716320621],\n",
        "          [2.012852249247597, 1.3896718089768398, 0.4029796624500576, 1.7892066150162698, 1.7408773929711023, 1.453658166367923],\n",
        "          [5.187525299382937, 1.5012804505254305, 0.31773293258909385, 1.9919799584135067, 2.195467787476551, 2.079338452420637],\n",
        "          [2.8607726131662563, 2.1738019089781915, 0.016666666666666666, 2.269787578072531,3.310713156183941, 2.3602722601254125]]"
      ],
      "metadata": {
        "id": "8SkVWlnNykI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_nodam = [[1.2, 1.2047619047619047, 1.2047619047619047],\n",
        "             [1.2049999999999998, 1.209767441860465, 1.2047619047619047],\n",
        "             [1.1800000000000002, 1.1847368421052633, 1.1847368421052633],\n",
        "             [1.2049999999999998, 1.209767441860465, 1.209767441860465],\n",
        "             [1.21, 1.2147727272727271, 1.209767441860465]\n",
        "             ]"
      ],
      "metadata": {
        "id": "1uySPsu6HIUp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}