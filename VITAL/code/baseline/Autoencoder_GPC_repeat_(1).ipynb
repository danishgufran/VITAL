{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8P8MrJje-6OU",
        "outputId": "d158c19b-f88b-4360-b44e-81741551f6ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'private'...\n",
            "remote: Enumerating objects: 1521, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 1521 (delta 0), reused 5 (delta 0), pack-reused 1516\u001b[K\n",
            "Receiving objects: 100% (1521/1521), 182.30 MiB | 16.45 MiB/s, done.\n",
            "Resolving deltas: 100% (738/738), done.\n",
            "Checking out files: 100% (1655/1655), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/danishgufran/private.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-8f3W4rWwpS",
        "outputId": "1a2d5d52-6b2e-4f9d-e0ed-09c6803ee800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'maril'...\n",
            "remote: Enumerating objects: 131, done.\u001b[K\n",
            "remote: Counting objects: 100% (131/131), done.\u001b[K\n",
            "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
            "remote: Total 131 (delta 88), reused 84 (delta 58), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (131/131), 2.78 MiB | 12.47 MiB/s, done.\n",
            "Resolving deltas: 100% (88/88), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -rf maril\n",
        "!git clone --depth=1 https://danishgufran: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@github.com/danishgufran/maril.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htSWqSo1WkIB"
      },
      "outputs": [],
      "source": [
        "# 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"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ti6kf1RT_UbR"
      },
      "outputs": [],
      "source": [
        "from maril.data import Devices, Floorplan, build_dataset\n",
        "from maril.helpers import compute_distances\n",
        "import copy\n",
        "from copy import deepcopy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Reshape\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D , LSTM, Attention\n",
        "from tensorflow.keras.losses import *\n",
        "from tensorflow.keras.optimizers import*\n",
        "import random as random\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EReVVxAlMmdo"
      },
      "outputs": [],
      "source": [
        "def build_model(input_shap):\n",
        "    \n",
        "    h1 = 150\n",
        "    h2 = 110\n",
        "    h3 = 30\n",
        "\n",
        "    autoencoder = Sequential([\n",
        "      tf.keras.Input(shape=(input_shape,)), # enc = 190\n",
        "     keras.layers.GaussianNoise(0.25),\n",
        "     keras.layers.Dropout(.2),\n",
        "    #  Dense(200, activation='relu'),\n",
        "    #  keras.layers.Dropout(.2),\n",
        "     Dense(h1, activation='relu'),\n",
        "     keras.layers.Dropout(.2),\n",
        "     Dense(h2, activation='relu'),\n",
        "     keras.layers.Dropout(.2),\n",
        "     Dense(h1, activation='relu'),\n",
        "\n",
        "     Dense(input_shape, activation='sigmoid')                   \n",
        "    ])\n",
        "    # dr = Dropout(.2)(GN)\n",
        "    # encoded = Dense(200, activation='relu')(dr)\n",
        "    # dr1 = Dropout(.2)(GN)\n",
        "    # encoded = Dense(100, activation='relu')(encoded)\n",
        "    # dr2 = Dropout(.2)(GN)\n",
        "    # encoded = Dense(50, activation='relu')(encoded)\n",
        "    # dr3 = Dropout(.2)(GN)\n",
        "    # decoded = Dense(100, activation='relu')(encoded)\n",
        "    # dr4 = Dropout(.2)(GN)\n",
        "    # decoded = Dense(200, activation='relu')(decoded)\n",
        "    # decoded = Dense(input_shape, activation='sigmoid')(decoded) # recons = 203\n",
        "    # autoencoder = Model(model)\n",
        "\n",
        "    opt = Adam(learning_rate=0.001)\n",
        "\n",
        "    autoencoder.compile(loss=mse, # TODO: change to cross-entropy between two vectors\n",
        "                optimizer=opt,\n",
        "                metrics=['accuracy'])\n",
        "    \n",
        "    return autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wp7za2vc_ZBX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1b1926f-e6c5-4c3a-d431-9d95032e0dfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "one (164, 176)\n",
            "(164, 176)\n",
            "(164, 342)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3645: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self[col] = value\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(164, 335)\n",
            "(656, 335)\n",
            "[18.07486338939948]\n",
            "[18.07486338939948]\n",
            "[18.502974088571868]\n",
            "[18.502974088571868]\n",
            "[18.502974088571868]\n",
            "[18.502974088571868]\n",
            "one (164, 342)\n",
            "(164, 176)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3645: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self[col] = value\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(164, 342)\n",
            "(164, 335)\n",
            "(656, 335)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/gaussian_process/kernels.py:437: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[17.221253148437555]\n",
            "[17.221253148437555]\n",
            "[17.645916080282284]\n",
            "[17.645916080282284]\n",
            "[17.645916080282284]\n",
            "[17.645916080282284]\n",
            "one (164, 335)\n",
            "(164, 176)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3645: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self[col] = value\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(164, 342)\n",
            "(164, 335)\n",
            "(656, 335)\n",
            "[18.07486338939948]\n",
            "[18.07486338939948]\n",
            "[18.502974088571868]\n",
            "[18.502974088571868]\n",
            "[18.502974088571868]\n",
            "[18.502974088571868]\n",
            "one (168, 159)\n",
            "(168, 159)\n",
            "(168, 271)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3645: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self[col] = value\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(168, 256)\n",
            "(672, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/gaussian_process/kernels.py:437: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12.788722549420939]\n",
            "[12.788722549420939]\n",
            "[12.630845280829753]\n",
            "[12.630845280829753]\n",
            "[12.764913025611415]\n",
            "[12.764913025611415]\n",
            "one (168, 271)\n",
            "(168, 159)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3645: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self[col] = value\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(168, 271)\n",
            "(168, 256)\n",
            "(672, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/gaussian_process/kernels.py:437: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9.846426875956801]\n",
            "[9.846426875956801]\n",
            "[9.90509873644276]\n",
            "[9.90509873644276]\n",
            "[9.823389670579145]\n",
            "[9.823389670579145]\n",
            "one (168, 256)\n",
            "(168, 159)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3645: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self[col] = value\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(168, 271)\n",
            "(168, 256)\n",
            "(672, 256)\n",
            "[10.119926641087144]\n",
            "[10.119926641087144]\n",
            "[10.447062608617575]\n",
            "[10.447062608617575]\n",
            "[10.096308873577401]\n",
            "[10.096308873577401]\n",
            "one (148, 177)\n",
            "(148, 177)\n",
            "(148, 251)\n",
            "(148, 239)\n",
            "(592, 239)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/gaussian_process/kernels.py:437: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10.241081180874138]\n",
            "[10.241081180874138]\n",
            "[9.99754755458724]\n",
            "[9.99754755458724]\n",
            "[9.99754755458724]\n",
            "[9.99754755458724]\n",
            "one (148, 251)\n",
            "(148, 177)\n",
            "(148, 251)\n",
            "(148, 239)\n",
            "(592, 239)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/gaussian_process/kernels.py:437: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6.163336815366722]\n",
            "[6.163336815366722]\n",
            "[6.224742481141972]\n",
            "[6.224742481141972]\n",
            "[6.224742481141972]\n",
            "[6.224742481141972]\n",
            "one (148, 239)\n",
            "(148, 177)\n",
            "(148, 251)\n",
            "(148, 239)\n",
            "(592, 239)\n",
            "[7.874837475723148]\n",
            "[7.874837475723148]\n",
            "[7.804593661832004]\n",
            "[7.804593661832004]\n",
            "[7.804593661832004]\n",
            "[7.804593661832004]\n",
            "one (168, 264)\n",
            "(168, 264)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3645: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self[col] = value\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(168, 498)\n",
            "(168, 406)\n",
            "(672, 406)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/gaussian_process/kernels.py:437: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6.402949275527719]\n",
            "[6.402949275527719]\n",
            "[6.526840453684212]\n",
            "[6.526840453684212]\n",
            "[6.526840453684212]\n",
            "[6.526840453684212]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3645: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self[col] = value\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "one (168, 498)\n",
            "(168, 264)\n",
            "(168, 498)\n",
            "(168, 406)\n",
            "(672, 406)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/gaussian_process/kernels.py:437: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6.666754535759131]\n",
            "[6.666754535759131]\n",
            "[6.728262826988554]\n",
            "[6.728262826988554]\n",
            "[6.728262826988554]\n",
            "[6.728262826988554]\n",
            "one (168, 406)\n",
            "(168, 264)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3645: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self[col] = value\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(168, 498)\n",
            "(168, 406)\n",
            "(672, 406)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/gaussian_process/kernels.py:437: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6.969936364533376]\n",
            "[6.969936364533376]\n",
            "[7.005159901249919]\n",
            "[7.005159901249919]\n",
            "[7.005159901249919]\n",
            "[7.005159901249919]\n",
            "one (172, 274)\n",
            "(172, 274)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3645: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self[col] = value\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(172, 427)\n",
            "(172, 389)\n",
            "(688, 389)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/gaussian_process/kernels.py:437: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6.63954916037336]\n",
            "[6.63954916037336]\n",
            "[6.568235795620353]\n",
            "[6.568235795620353]\n",
            "[6.639003097523472]\n",
            "[6.639003097523472]\n",
            "one (172, 427)\n",
            "(172, 274)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3645: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self[col] = value\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(172, 427)\n",
            "(172, 389)\n",
            "(688, 389)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/gaussian_process/kernels.py:437: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6.63954916037336]\n",
            "[6.63954916037336]\n",
            "[6.568235795620353]\n",
            "[6.568235795620353]\n",
            "[6.639003097523472]\n",
            "[6.639003097523472]\n",
            "one (172, 389)\n",
            "(172, 274)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:3645: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  self[col] = value\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(172, 427)\n",
            "(172, 389)\n",
            "(688, 389)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/gaussian_process/kernels.py:437: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9.510224971440904]\n",
            "[9.510224971440904]\n",
            "[9.408731896715198]\n",
            "[9.408731896715198]\n",
            "[9.55710772155575]\n",
            "[9.55710772155575]\n"
          ]
        }
      ],
      "source": [
        "##########################\n",
        "# OFFLINE PHASE\n",
        "###########################\n",
        "m =[]\n",
        "s=[]\n",
        "devices = ['i12p','pxl4','nk7']\n",
        "path = ['engr0', 'engr1', 'glover', 'sciences', 'libstudy']\n",
        "for floorplan in path:\n",
        "  for train_device in devices:\n",
        "\n",
        "    # dev = ['HTC','LG','MOTO','OP3','S7']\n",
        "    # for d in dev:\n",
        "    train_df, test_df, train_waps, lbl2cords = build_dataset(\n",
        "        train_device,\n",
        "        floorplan,\n",
        "    )\n",
        "\n",
        "    td = 'i12p'\n",
        "    train_df_rst_1, _, train_macs_rst_1, lbl2cord_rst_1 = build_dataset(\n",
        "      td,\n",
        "      floorplan,\n",
        "  )\n",
        "    missing_waps_rst = list(set(train_waps) - set(train_macs_rst_1))\n",
        "    _df = train_df_rst_1.copy()  # supresses fragmented df warning\n",
        "    _df[missing_waps_rst] = -100\n",
        "    train_y = _df[\"label\"].values.flatten()\n",
        "    _df = _df.drop(columns=['label','x','y'])\n",
        "    _df = (_df[:] + 100)/100\n",
        "    train_x = _df[:].values.astype(float)\n",
        "    \n",
        "\n",
        "    print('one', train_x.shape)\n",
        "\n",
        "    dev = ['i12p','pxl4','nk7']\n",
        "    for d in dev:\n",
        "      # if self.floorplan == 'engr0':\n",
        "\n",
        "      get_train, _, get_mac, get_lbl2cord = build_dataset(\n",
        "        d,\n",
        "        floorplan,\n",
        "    )\n",
        "      missing_waps_new = list(set(get_mac) - set(train_macs_rst_1))\n",
        "      col = train_df_rst_1.copy()  # supresses fragmented df warning\n",
        "      col[missing_waps_new] = -100\n",
        "      temp_y = col[\"label\"].values.flatten()\n",
        "      col = col.drop(columns=['label','x','y'])\n",
        "\n",
        "      col = (col[:] + 100)/100\n",
        "      temp_x = col[:].values.astype(float)\n",
        "\n",
        "\n",
        "      # autoencoder = build_model(temp_x.shape[1], temp_x)\n",
        "      # temp_x = autoencoder.predict(temp_x)\n",
        "\n",
        "\n",
        "\n",
        "      train_x = np.resize(train_x,(train_y.shape[0],temp_x.shape[-1]))\n",
        "      print(temp_x.shape)\n",
        "      train_x = np.concatenate((train_x, temp_x), axis=0)\n",
        "      train_y = np.concatenate((train_y, temp_y), axis=0)\n",
        "    print(train_x.shape)\n",
        "\n",
        "    input_shape = train_x.shape[1] # input = 203\n",
        "\n",
        "    # autoencoder = build_model(input_shape)\n",
        "\n",
        "    # history = autoencoder.fit(train_x, train_x,\n",
        "    #                 epochs = 10,\n",
        "    #                 validation_split = 0.30,\n",
        "    #                 shuffle = True, \n",
        "    #                 verbose = 0, \n",
        "    #                 callbacks=[tf.keras.callbacks.EarlyStopping(patience=200, min_delta=0.001)])\n",
        "\n",
        "    # #print(history.history)\n",
        "\n",
        "    # pred = autoencoder.predict(train_x)\n",
        "\n",
        "    # train GPC model\n",
        "    kernel = 1.0 * RBF(1.1)\n",
        "    gpc = GaussianProcessClassifier(kernel = kernel, random_state=0).fit(train_x, train_y)\n",
        "    #print(\"offline gpc score\", gpc.score(train_x, train_y))\n",
        "    #######################\n",
        "    # ONLINE PHASE\n",
        "    ##########################\n",
        "\n",
        "\n",
        "    reps = 2\n",
        "\n",
        "    test_devices =['i12p','pxl4','nk7']\n",
        "    for dev_name in test_devices:\n",
        "      # build data\n",
        "      train_df, test_df, macs, lbl2cords = build_dataset(\n",
        "          dev_name,\n",
        "          floorplan\n",
        "      )\n",
        "\n",
        "      missing_waps = list(set(train_macs_rst_1) - set(macs))\n",
        "      test_df = test_df.copy()  # supresses fragmented df warning\n",
        "      test_df[missing_waps] = -100\n",
        "      test_y = test_df[\"label\"].values.flatten()\n",
        "      test_df.drop(columns=['label','x','y'])\n",
        "      test_df = (test_df[:] + 100)/100\n",
        "      test_x = test_df[train_macs_rst_1].values.astype(float)\n",
        "      \n",
        "      test_x = np.resize(test_x,(test_x.shape[0],temp_x.shape[-1]))\n",
        "      \n",
        "      pred_probs = None\n",
        "      for i in range(0, reps):\n",
        "\n",
        "        # produce probabilities\n",
        "        pred = gpc.predict_proba(test_x)\n",
        "    \n",
        "        if pred_probs is None:\n",
        "          pred_probs = pred\n",
        "        else:\n",
        "          pred_probs += pred\n",
        "\n",
        "        # end of reps\n",
        "        pred_y = np.argmax(pred_probs,axis =-1)\n",
        "\n",
        "        # errors\n",
        "        errors = compute_distances(pred_y, test_y, lbl2cords)\n",
        "        mean = np.mean(errors)\n",
        "        sd = np.std(errors)\n",
        "\n",
        "        #print(f\"train: {train_device} - test: {test_dev} - Floorplan: {floorplan} : {mean:.2f} - {sd:.2f}\")\n",
        "        m.append(mean)\n",
        "        s.append(sd)\n",
        "        print(m)\n",
        "\n",
        "        m.clear()\n",
        "        s.clear()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06p3gFCQYEs8"
      },
      "outputs": [],
      "source": [
        "s = [2.3127016804943565, 2.47066528369349, 2.0710467940688186, 2.442906247449625, 2.7747017651196235, 2.3398743021256254]\n",
        "[2.3463821848409667, 2.5777250074073788, 2.3690865939354873, 2.470897992306357, 2.6427897029243193, 2.348751498928457]\n",
        "[6.141401147107631, 6.0657814290462015, 6.184465186483393, 6.185817934531693, 6.276793605912727, 6.147874098107582]\n",
        "[1.9509635470114164, 1.864611040242088, 1.8724954369513334, 1.993119127515661, 1.7250516235966415, 2.093511331930462]\n",
        "[1.9597838946040298, 1.8338981824038485, 2.0415247058510726, 2.302956047254154, 2.1221576552943744, 1.6024194742214166]\n",
        "[2.1476713138633583, 2.3651226587422505, 2.2499860480310825, 2.525411073149808, 3.01286791178186, 1.805372437068593]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZqPWvlrYEvU"
      },
      "outputs": [],
      "source": [
        "s1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFHeLrpUYExp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0narpnPYE0O"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFdaq-enYE2U"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIFJLIxUYE4p"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxZG1e48YE6v"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Om3qROcpYE9Y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "es9iIMpmXfxH"
      },
      "outputs": [],
      "source": [
        "    ##########################\n",
        "    # OFFLINE PHASE\n",
        "    ###########################\n",
        "devices = ['LG','BLU','HTC','MOTO','S7','OP3']\n",
        "path = ['engr0', 'engr1', 'glover', 'libstudy', 'sciences']\n",
        "for floorplan in path:\n",
        "  for train_device in devices:\n",
        "    # train device and floorplan\n",
        "    # build model\n",
        "\n",
        "      tf.keras.backend.clear_session()\n",
        "\n",
        "    train_df, _, macs, lbl2cord = build_dataset(\n",
        "        train_device,\n",
        "        floorplan,\n",
        "    )\n",
        "\n",
        "    train_x, train_y = train_df[macs].values, train_df[\"label\"].values\n",
        "\n",
        "    input_shape = train_x.shape[1] # input = 203\n",
        "\n",
        "    autoencoder = build_model(input_shape)\n",
        "\n",
        "    history = autoencoder.fit(train_x, train_x,\n",
        "                    epochs = 1000,\n",
        "                    validation_split = 0.30,\n",
        "                    shuffle = True, \n",
        "                    verbose = 0, \n",
        "                    callbacks=[tf.keras.callbacks.EarlyStopping(patience=200, min_delta=0.001)])\n",
        "\n",
        "    print(history.history)\n",
        "\n",
        "    pred = autoencoder.predict(train_x)\n",
        "\n",
        "    # train GPC model\n",
        "    kernel = 1.0 * RBF(0.7)\n",
        "    gpc = GaussianProcessClassifier(kernel = kernel).fit(train_x, train_y)\n",
        "    print(\"offline gpc score\", gpc.score(train_x, train_y))\n",
        "    #######################\n",
        "    # ONLINE PHASE\n",
        "    ##########################\n",
        "\n",
        "    test_devices = Devices.devices\n",
        "    reps = 3\n",
        "\n",
        "    for test_dev in test_devices: \n",
        "      # test data is read once\n",
        "      _, test_df, online_macs, lbl2cord = build_dataset(\n",
        "        test_dev,\n",
        "        floorplan,\n",
        "      )\n",
        "\n",
        "      missing = list(set(macs) - set(online_macs))\n",
        "      test_df = test_df.copy()\n",
        "      test_df[missing] = float(0)\n",
        "\n",
        "      test_x, test_y = test_df[macs].values, test_df[\"label\"].values\n",
        "      \n",
        "      pred_probs = None\n",
        "      for i in range(0, reps):\n",
        "\n",
        "        # produce probabilities\n",
        "        pred = gpc.predict_proba(test_x)\n",
        "    \n",
        "        if pred_probs is None:\n",
        "          pred_probs = pred\n",
        "        else:\n",
        "          pred_probs += pred\n",
        "\n",
        "      # end of reps\n",
        "      pred_y = np.argmax(pred_probs,axis =-1)\n",
        "\n",
        "      # errors\n",
        "      errors = compute_distances(pred_y, test_y, lbl2cord)\n",
        "      mean = np.mean(errors)\n",
        "      sd = np.std(errors)\n",
        "\n",
        "      print(f\"train: {train_device} - test: {test_dev} - Floorplan: {floorplan} : {mean:.2f} - {sd:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MSEPiEBdk6h"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLjnaj6f7Fwe"
      },
      "outputs": [],
      "source": [
        "all_error = [[0.0002, 4.052083333333333, 8.79861111111111, 6.152777777777778, 7.277777777777778, 4.239583333333333],\n",
        "             [2.7256944444444446, 0.00015, 2.7569444444444446, 3.875, 2.2743055555555554, 3.28125],\n",
        "             [2.0, 3.079861111111111, 0.001909722, 4.25, 2.517361111111111, 3.9340277777777777],\n",
        "             [2.8055555555555554, 2.59375, 2.2847222222222223, 0.06597222222222222, 2.3541666666666665, 2.4409722222222223],\n",
        "             [2.2222222222222223, 3.8680555555555554, 7.802083333333333, 3.7291666666666665, 0.0002, 4.190972222222222],\n",
        "             [3.0347222222222223, 2.857638888888889, 3.0034722222222223, 3.34375, 1.9930555555555556, 0.024305555555555556]           \n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMsK_fojIOcL"
      },
      "outputs": [],
      "source": [
        "import seaborn as sb\n",
        "fig, ax = plt.subplots(figsize=(5,5))\n",
        "x_axis_labels = ['LG','BLU','HTC','MOTO','S7','OP3'] # labels for x-axis\n",
        "y_axis_labels = ['LG','BLU','HTC','MOTO','S7','OP3'] # labels for y-axis\n",
        "sb.heatmap(all_error, xticklabels=x_axis_labels, yticklabels=y_axis_labels,annot=True, square=True, ax=ax, fmt='.4g')\n",
        "plt.title(\"AE Model for Office Data\")\n",
        "plt.xlabel('Testing Devices',)\n",
        "plt.ylabel('Training Devices',)\n",
        "plt.yticks(rotation=0,fontsize=16);\n",
        "plt.xticks(fontsize=12);\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7H0cMJbgfLKZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}